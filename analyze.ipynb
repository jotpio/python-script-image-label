{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.cbook as cbook\n",
    "#from scipy.misc import imread\n",
    "from matplotlib.pyplot import imread\n",
    "\n",
    "from importlib import reload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import AnalyzeAnnotations as aa\n",
    "import PlotAnnotations as pa\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "pd.options.display.max_colwidth = 400\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\"> Load sloth jsons </span> into array of pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load all json files from datapath into array of pandas dataframes\n",
    "# path = './data/20191031_MIxedSpecies_Photos_final_annotations/'\n",
    "# path = './data/testdata/'\n",
    "json_path = './data/MEX_Sloth/Survey/'\n",
    "imgs_path = './data/MEX_Sloth/Survey_photos/'\n",
    "\n",
    "\n",
    "print(f\"{time.strftime('%d/%m/%Y, %H:%M:%S', time.localtime())}:      Path to be loaded: {json_path}\")\n",
    "df_stats, all_df, json_files = aa.loadAllJSONSFromPath(json_path)\n",
    "number_imgs = len([file for file in os.listdir(imgs_path) if os.path.isfile(os.path.join(imgs_path, file))])\n",
    "print('Number of json files loaded: ' + str(len(all_df)))\n",
    "print(f\"Number of files in image folder: {number_imgs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate abundance of classes + split positions + average pos column + length column + direction (rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# update df_stats with abundance of classes\n",
    "df_stats = aa.getNumberOfClassesInDFs(df_stats, all_df, json_files)\n",
    "# extract head and tail positions + calculate average of head and tail + calc length + calc polarization\n",
    "df_allsplit = aa.splitPos(df_stats, all_df, json_files)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df_stats)\n",
    "print(f\"\\n{df_allsplit[0].head(5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats of dataframe df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.describe()\n",
    "df_stats.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neighbours\n",
    "\n",
    "* Calculate distance matrix and find neighbors\n",
    " * finds neighbors using a distance matrix and filtering out neighbours over two times average length and four times average length\n",
    "* Add number of class neighbors column\n",
    " * adds columns for each fish containing the number of neighbors of each class (for distance d2/av2 and d4/av4)\n",
    "* Add same class neighbors percentage and average number of neighbors (per class and total) to stats \n",
    "* degree: mean number of fish in radius of 2 body lengths\n",
    "* density: degree / number of fish in image\n",
    "* nnd: euclidean distances to nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_allsplit, df_stats, data_numbers = aa.neighbor_calculations(df_allsplit, df_stats, json_files, imgs_path)\n",
    "# \n",
    "# check sample\n",
    "#\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "\n",
    "print(df_allsplit[4].head(2))\n",
    "df_stats.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add average length, direction and polarization to stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = aa.pop_stats_pol_dir_len(df_allsplit, df_stats)\n",
    "\n",
    "df_stats.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./output/stats'):\n",
    "            os.makedirs('./output/stats')\n",
    "\n",
    "for i, df_split in enumerate(df_allsplit):\n",
    "    number = df_split.number\n",
    "    df_split.to_csv('./output/stats/' + str(number) + '.csv')\n",
    "\n",
    "df_stats.to_csv('./output/summary.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test one image\n",
    "index=4\n",
    "#print(json_files)\n",
    "number = df_allsplit[index].number\n",
    "imgpath = pa.get_imgpath_for_number(number, imgs_path)\n",
    "pa.plot_pos_cat_img(df_allsplit[index], imgpath, show=True, save=True)\n",
    "pa.plot_pos_ori_cat(df_allsplit[index], show=True, save=True)\n",
    "pa.plot_pos_ori_cat_img(df_allsplit[index], imgpath, show=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot positions of all read files\n",
    "pa.plot(df_allsplit, json_files, imgs_path, SHOW=False, SAVE=True)\n",
    "\n",
    "print(f\"{time.strftime('%d/%m/%Y, %H:%M:%S', time.localtime())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* refactor much\n",
    "* convert .ipynb to .py\n",
    "* create exe file from python script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angles = [0.163618, -0.208563, -0.246237, 0.379256, 0.189199]\n",
    "angles_deg = np.degrees(angles)\n",
    "\n",
    "print(angles_deg)\n",
    "\n",
    "msin = np.mean(np.sin(angles))\n",
    "mcos = np.mean(np.cos(angles))\n",
    "np.degrees(np.arctan2(msin,mcos))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [[1, 0],[0.5, 1]]\n",
    "v_normalized = preprocessing.normalize(v, norm='l1')\n",
    "print(v_normalized)\n",
    "v_mean_unit = np.mean(v_normalized, axis=0)\n",
    "print(v_mean_unit)\n",
    "\n",
    "\n",
    "ord = 2\n",
    "print(np.linalg.norm(v_mean_unit, ord=ord))\n",
    "print(np.square(np.linalg.norm(v_mean_unit, ord=ord)))\n",
    "\n",
    "\n",
    "v = [[1, 0],[1, 0.5]]\n",
    "v_normalized = preprocessing.normalize(v, norm='l1')\n",
    "print(v_normalized)\n",
    "v_mean_unit = np.mean(v_normalized, axis=0)\n",
    "print(v_mean_unit)\n",
    "\n",
    "\n",
    "ord = 2\n",
    "print(np.linalg.norm(v_mean_unit, ord=ord))\n",
    "print(np.square(np.linalg.norm(v_mean_unit, ord=ord)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = [[0,2], [10,0], [-10,0]]\n",
    "v = [[1,0], [1,1]]\n",
    "print(f\"pos:\\n{v}\")\n",
    "v_normalized = preprocessing.normalize(v, norm='max')\n",
    "print(f\"normalized_pos:\\n{v_normalized}\")\n",
    "v_mean = np.mean(v_normalized, axis=0)\n",
    "print(f\"mean normalized vector: {v_mean.tolist()}\")\n",
    "pol = np.linalg.norm(v_mean, ord=np.inf)\n",
    "# pol = np.linalg.norm(v_mean)\n",
    "\n",
    "print(f\"pol: {pol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = [[0,2], [10,0], [-10,0]]\n",
    "v = [[0,1], [1,1]]\n",
    "\n",
    "print(f\"pos:\\n{v}\")\n",
    "# # print(f\"magnitudes: {np.linalg.norm(v, axis=0)}\")\n",
    "# v_normalized = preprocessing.normalize(v, norm='l2')\n",
    "# print(f\"normalized_pos:\\n{v_normalized}\")\n",
    "# v_mean = np.mean(v_normalized, axis=0)\n",
    "# print(f\"mean normalized vector: {v_mean.tolist()}\")\n",
    "# pol = np.linalg.norm(v_mean, ord=np.inf)\n",
    "# # pol = np.linalg.norm(v_mean)\n",
    "\n",
    "unit_vectors = preprocessing.normalize(v, norm='l2')\n",
    "print(f\"unit vectors:\\n{unit_vectors}\")\n",
    "\n",
    "mean_of_sum_of_unitv = np.mean(unit_vectors, axis=0)\n",
    "print(f\"mean unit vector: {mean_of_sum_of_unitv.tolist()}\")\n",
    "\n",
    "mag_meanv = np.linalg.norm(mean_of_sum_of_unitv)\n",
    "\n",
    "pol = mag_meanv\n",
    "\n",
    "print(f\"pol: {pol}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v1 = np.random.rand(10000,2)\n",
    "# v2 = np.random.rand(10000,2)\n",
    "\n",
    "v1 = np.random.uniform(-1, 1, (10000, 2))\n",
    "v2 = np.random.uniform(-1, 1, (10000, 2))\n",
    "\n",
    "pols = []\n",
    "for idx, v in enumerate(v1):\n",
    "    twov = [v, v2[idx]]\n",
    "    unit_vectors = preprocessing.normalize(twov, norm='l2')\n",
    "    mean_of_sum_of_unitv = np.mean(unit_vectors, axis=0)\n",
    "    mag_meanv = np.linalg.norm(mean_of_sum_of_unitv)\n",
    "    pols.append(mag_meanv)\n",
    "#     v_normalized = preprocessing.normalize(twov, norm='l1')\n",
    "#     v_mean = np.mean(v_normalized, axis=0)\n",
    "#     pol = np.linalg.norm(v_mean, ord=np.inf)\n",
    "#     pols.append(pol)\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(pols, bins=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sciencedirect.com/science/article/pii/S0960982217310138\n",
    "\n",
    "v1 = np.random.uniform(-1, 1, (1000, 2))\n",
    "v2 = np.random.uniform(-1, 1, (1000, 2))\n",
    "\n",
    "pols = []\n",
    "\n",
    "for idx, v in enumerate(v1):\n",
    "    angle1 = np.arctan2(v[1], v[0])\n",
    "    angle2 = np.arctan2(v2[idx][1], v2[idx][0])\n",
    "    \n",
    "    sm = (np.square(np.sin(angle1) + np.sin(angle2))) + (np.square(np.cos(angle1) + np.cos(angle2)))\n",
    "    rt = np.sqrt(sm)\n",
    "    pol = rt/2\n",
    "    \n",
    "    pols.append(pol)\n",
    "\n",
    "plt.hist(pols)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"test12test1234.jpg\"\n",
    "a[-8:-4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
